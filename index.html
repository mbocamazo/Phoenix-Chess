<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8' />
    <meta http-equiv="X-UA-Compatible" content="chrome=1" />
    <meta name="description" content="Phoenix-Chess : Chess AI created for Software Design Final Project" />

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>Phoenix-Chess</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/mbocamazo/Phoenix-Chess">View on GitHub</a>

          <h1 id="project_title">Phoenix-Chess</h1>
          <h2 id="project_tagline">Chess AI created for Software Design Final Project</h2>

            <section id="downloads">
              <a class="zip_download_link" href="https://github.com/mbocamazo/Phoenix-Chess/zipball/master">Download this project as a .zip file</a>
              <a class="tar_download_link" href="https://github.com/mbocamazo/Phoenix-Chess/tarball/master">Download this project as a tar.gz file</a>
            </section>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <p>This is the project page for Phoenix-Chess, a Chess AI written by Michael Bocamazo (<a href="https://github.com/mbocamazo" class="user-mention">@mbocamazo</a>) and Dennis Chen (<a href="https://github.com/dennis-chen" class="user-mention">@dennis-chen</a>) for Software Design Spring 2014, Olin College of Engineering.</p>

<p>Project Proposal:</p>

<p>The plan for Phoenix-Chess is to create a chess AI that can be refined and extended with machine learning techniques.  We will adopt the standard tree-search, minimaxing, alpha-beta pruning structure; implementation of these elements is the Software Engineering work.  The original AI design and CS work will come in when constructing the board evaluation function and pruning heuristics.  The board evaluation function will quantify material, activity of pieces, pawn value, pawn structure, board control, king safety, initiative, and a few features of the board state common to both players such as volatility, and an open/closed position.  Material, activity, and board control can have interrelated evaluations that dynamically weight the pieces.  The pruning function will eliminate branches that are judged to have a low probability of viability to speed tree search and thus allow for deeper evaluations.  We will also need to add a function to limit the search depth based on time available.  Once this groundwork has been laid, we can refine the weights of our board evaluation and pruning functions using machine learning, such as simple hill-climbing or possibly genetic algorithms with the extension of constructing new features.  We could also access master game databases and refine the weights to best approximate master level moves given a certain position.  If these tasks are done satisfactorily, we can try to add an opening book.  The greatest challenges we envision are the feature construction from primitive relationships between game elements, and interaction and analysis with game databases.</p>

<p>If we were to have an Angel Adviser, it would be best if they had experience with AI, chess, or ML.</p>

<p>Our proposed deliverables can be broken down as follows:</p>

<p>Minimum Deliverable: A chess board evaluation function/tree search shell that searches at least 4 total moves ahead when making its choices. </p>

<p>Second Deliverable: Tree search pruning heuristic (suitable for machine learning)</p>

<p>Third Deliverable: Use ML to refine board weight function</p>

<p>Fourth Deliverable: Search and learn on databases of master level games to refine the board weight function</p>

<p>Fifth Deliverable: Use genetic algorithms to construct features within the board weight functions</p>

<p>Further extensions: iterate from deliverables 2 through 5 to improve the program.  Add an opening book.</p>

<p>The first step is to create an AI that does an exhaustive search at a certain depth with a basic board evaluation function.</p>

<p>This project will be done by Michael Bocamazo and Dennis Chen without collaboration from other groups.  The project repo is connected to this page at <a href="https://github.com/mbocamazo/Phoenix-Chess">https://github.com/mbocamazo/Phoenix-Chess</a>.</p>

<p></p>
<p>




Design</p>
<p> To get started on our project, the first thing to do was to find a working python chess implementation. We settled on using the most complete chess implementation we could find because a chess AI that can't deal with castling, pawn promotion, and en passant isn't a terribly useful AI. The trade-off was speed and that the code had no implementation for AI and was not done in an Object-Oriented Way. We decided that dealing with this was better than implementing castling, pawn promotion, etc. ourselves.</p>
<p>We've spent the last two weeks refactoring the previous code into a MVC model to make it easier to interface with. We then implemented a way for two chess AIs to play against each other. We got AIs that made random moves to play against each other without a problem. We're currently trying to implement tree search for the AI. (Tree search is the standard textbook way of having AI decide on the next move in a chess game). The interesting space where we'll start to make algorithm and design decisions is in the future, when we write “pruning” and “quiescence” functions that determine when to search deeper into the tree (look further into the possible future moves) and when to stop looking any further. Writing complex “board evaluation” functions, which the AI uses to determine how “good” a board is for itself, is a possibility as well.</p>
<p> Our most significant design decision so far was in choosing the chess implementation, which determines the speed of our chess program and thus how far our AI can look into the game tree. It is a inefficient implementation, not written for speed, but it's the best complete one we found. It looks like not many people do serious chess AI work in python because it's a higher level and slower language. It's okay for us though, we aren't planning on writing a competitive Chess AI. Instead, the main goal is to explore how Chess AI can be programmed with Machine Learning (ML).</p>
<p> We kept our goal of ML in mind when implementing the tree search algorithm: Chess AIs take board evaluation, pruning and quiescence functions as input when they are instantiated. This way, for genetic algorithms, we can initialize Chess AIs with differently weighted pruning, quiescence, and board evaluation functions.       </p>
<p> Our development plan is to get tree search working, get a basic (and textbook) pruning algorithm called alpha-beta pruning working, and to look into the possibility of implementing data structures called transposition tables that can save a lot of time by having the AI “remember” board states that occur frequently. (Transposition tables are pretty complex to implement so we might ignore it in the interest of getting to the ML part of the project). Finally, we'll implement a basic quiescence function. At that point, we'll have our minimum deliverable, a not-terrible Chess AI. We think we want to use ML to dynamically change the board evaluation function as a game progresses, but the ML direction isn't set in stone yet. Both team members have been involved in coding and making design decisions and we'll continue to do so and pair program.  </p>

<p>UML Class Diagram</p>
<p>To implement genetic algorithms, we created tournament and game classes to have AI compete against each other. Our tournaments take a swiss tournament form, where the best AI are paired
  against each other, and the ranking of the AI player is modified based on how many games it wins or loses. We refactored the code that the original author of the chess program wrote in order to
  put it into a nice MVC model. Then we built in AI and human player classes and the classes needed for genetic algorithms mentioned earlier. AI are differentiated by the randomized
  board evaluation functions and search extension functions that they achieve. Those functions control how the AI quantifies how "good" a board is for either player, and also determines how deep
  the AI will search into the game tree.
  <img src="https://github.com/mbocamazo/Phoenix-Chess/blob/gh-pages/images/UML_class_diagram.png?raw=true" alt="UML diag">
</p>
<p>Design Refinement</p>
<p>Our minimum deliverable of a decent chess AI has been achieved, and we have started comparison of AIs based on use of different evaluation functions.</p>
<p>As we have progressed into the machine learning-genetic algorithms stage, we have added class structures to support it.  A tournament class with tournament AIs and Games was added.  Games include two players, which include AIs or Humans.  These classes have a Chess Model, which holds a Controller and a View.  The AIs have modules of evaluation and pruning functions, which are not proper classes but are selected as attributes of an AI.  </p>
<p>The board representation of a list of strings is much more time-intensive for calculations that standard 'bit boards', which encode all of the locations of the pieces as bits in binary integers specific to each piece class.  This representation would constitute a great deal of work to change, and because we are working in python, we will not achieve the efficiencies of professional AIs. For this reason, we've accepted the search depth of 4-6 as what we'll achieve in a relatively quick game. The AIs constructed all followed the same general pattern, so unit tests for adherence to certain expected moves were unnecessary after the excessive case checking through playtesting validation.  If large changes in the AI decision process were made, unit tests for expected moves would be necessary.</p>
<p>The use of the computing cluster requires some small additions to pass the games correctly.  Manual multithreading of games may be necessary to run in a smaller time frame instead of all as a single sequence.</p>
<p>Data structures within many of the chess model functions were changed significantly to make performance gains in calculations, allow for deeper searches and more complicated evaluation functions.  Cases in which the position of the king needed to be tested for check were consolidated for each branch within the tree search.  As a result, the search with positional evaluation went from calculating 700 nodes per second to upwards of 1500 nodes per second.    </p>
<p>The most significant algorithm used is alpha-beta pruning within the tree search.  This may be explained simply in the following sequence, with Alice and Bob as players:  "If Alice knows she can do better with move #1 than a result of one of Bob's responses to move #2, Alice won't choose move #2, so stop searching" (M. Bocamazo).  With evaluating the moves in the order expected to generate cutoffs (stops in the search) more frequently, the search can effectively halve the exponent on the order of the bounding function.</p>
<p>Menus should be added at the end of the project for greater user friendliness and usability.</p>
<p> Final Design Reflection</p>
<p> For a simplified and faster position evaluation, we chose to use piece-square tables for the pawns, knights, bishops, and kings.  A piece-square table takes the position of each of those pieces on the board and returns a static score based on very simple development principles. The starting squares of the knights and bishops are weighted negatively to encourage development.  The knight is weighted higher at the center of the board, and the bishops on the second-to-edge squares and center.  Both are negative on the edges, the knights more heavily so. The kings have two tables, one for the opening and midgame that keeps them on the behind the pawns and encourages castling, and one for the endgame that encourages movement to the center so the king can fight for its control.</p>
<p> Pair-wise weights were also implemented.  Because the goal of the genetic algorithm experiment is to discover weights of pieces and compare those to the conventional weights, the GA will be run on the pair-wise weights as well to actually discover them.  It is generally understood that there is some material value to the bishop pair, and that the queen-knight pair is more valuable than the queen-bishop pair.  If the GA is sensitive enough to recognize and converge on values for this, it would be quite interesting.  A problem in the GA is that the pair-wise weights are coupled with the static piece weights, so a good set of static weights could carry bad weights - considering the schemata theorem and the building block hypothesis, this isn't a problem - but within our experimental boundaries, it could be.</p>
<p> Running the genetic algorithms with parallel processing implemented required several design decisions.  A very simple annealing schedule (pattern for change in magnitude of the mutations as generations progress) was chosen - linear from one pawn at the beginning to zero at the final generation.  A slightly more complex one with a cooling state at the end was considered - mutation magnitude of zero, with only recombination for several generations.  However, for the number of runs we've done with a decent (more than 4) number of generations, we chose to use the very simplest first and then turn the knobs later.  A slightly unconventional recombination algorithm was chosen  - at random locations in the genome, the weight of a piece or a pair-wise weight is copied from a high-rank AI to a low-rank one.  This is different from the traditional operator in that usually a segment of the genome is copied over after or before a randomly chosen location.  For our purposes, the reduction in convergence speed shouldn't be too much of a problem.  A schema with length one is still a schema.  </p>
<p> Because our project turned into an exploration of AIs and GAs, we chose to forego any real GUI beyond that of the actual chess game.  An explanation of how to set the AI properties will be added in the readme.</p>
<p> We successfully achieved our minimum deliverable of an implementation of AI with alpha-beta pruning and material evaluation.  We're nearly done with one of our extension deliverables of implementation of GA, and we've solidly explored position evaluation.  Learning on master game data bases did not happen, but could happen later as part of personal interest exploration.  The data-scraping component would probably be time-consuming, which is why implementation of GA was chosen over it.  Progress through the project went at a fairly steady pace until interfacing with the cluster, which had something of a learning curve.  Hopefully we'll be able to do a few GA runs before Olin Expo to show them, and produce a graph of convergence (or non-convergence) of the piece weights over time within the population.  Such a graph would be a really solid representation of or GA exploration, and would provide a way to compare the parameter choices with the GA.  </p>
<p> To do this Chess AI project seriously next time, we would not use python and would use something like C++ and a bit-board representation of the game state so we could make use of bitwise operations to search through evaluations much more efficiently.  The decision to go with a string-based representation was appropriate, in retrospect, for the seriousness of testing that we wanted to do and the fact that the weights found and fully generalizable to other representations.  The division of labor was OK.  Dennis ended up 'holding the hammer' (doing most of the typing while pair-programming) and Mike (I) 'held the pencil' (reading about algorithms and writing pseudocode prototypes, and making more of the design decisions).  We probably should have alternated more, but I think it went with what each of us wanted to do.  I think the single best decision we made was to use cProfiler to examine the running time.  This led to 700 nodes/second evaluation with activity evaluation up to 2400 nodes/sec after rewriting many of the representation functions.  </p>
<p> Overall, we were pleased with how the project turned out, and we'll try to present some decent analysis of the GA for Olin Expo.</p>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">Phoenix-Chess maintained by <a href="https://github.com/mbocamazo">mbocamazo</a> and <a href="https://github.com/dennis-chen">dennis-chen</a></p>
        <p>Published with <a href="http://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

  </body>
</html>
